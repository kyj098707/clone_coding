{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "regex는 머지\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "import pandas as pd\n",
    "import regex as re\n",
    "from typing import Optional, Sequence\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split,KFold\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support,\\\n",
    "                             roc_auc_score,f1_score\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from transformers import Trainer, TrainingArguments, AutoModelForSequenceClassification,\\\n",
    "                        AutoModelForSequenceClassification,AutoTokenizer, EarlyStoppingCallback,\\\n",
    "                        AutoModel,AutoConfig,T5TokenizerFast,ElectraTokenizerFast,ElectraModel,\\\n",
    "                        T5ForConditionalGeneration\n",
    "\n",
    "import gc\n",
    "os.environ[\"TOKENIZERS_PARALLEISM\"] = \"false\"              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./dataset/\"\n",
    "\n",
    "train = pd.read_csv(os.path.join(data_dir,\"train.csv\")).drop(['ID'],axis=1)\n",
    "test = pd.read_csv(os.path.join(data_dir, \"test.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>문장</th>\n",
       "      <th>유형</th>\n",
       "      <th>극성</th>\n",
       "      <th>시제</th>\n",
       "      <th>확실성</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>누군가는 누군가는 살아남고 무대를 떠났다</td>\n",
       "      <td>사실형</td>\n",
       "      <td>긍정</td>\n",
       "      <td>과거</td>\n",
       "      <td>확실</td>\n",
       "      <td>사실형-긍정-과거-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>현재 약 200여 명의 한국생애설계사들이 교육컨설턴트 상담사 등으로 활동하고 있으며...</td>\n",
       "      <td>사실형</td>\n",
       "      <td>긍정</td>\n",
       "      <td>현재</td>\n",
       "      <td>확실</td>\n",
       "      <td>사실형-긍정-현재-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>한 활성화돼 말했다 업계의 어려움을 이해해주어 공항 면세점 임대료 감면을 연장해 주...</td>\n",
       "      <td>사실형</td>\n",
       "      <td>긍정</td>\n",
       "      <td>과거</td>\n",
       "      <td>확실</td>\n",
       "      <td>사실형-긍정-과거-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>캐릭터 나열 순서 설정 기능을 통해 각 이용자가 보유한 캐릭터 중 원하는 캐릭터를 ...</td>\n",
       "      <td>사실형</td>\n",
       "      <td>긍정</td>\n",
       "      <td>과거</td>\n",
       "      <td>확실</td>\n",
       "      <td>사실형-긍정-과거-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>정도로 관람객이 거의 없을 주말이지만 한적했다</td>\n",
       "      <td>사실형</td>\n",
       "      <td>긍정</td>\n",
       "      <td>과거</td>\n",
       "      <td>확실</td>\n",
       "      <td>사실형-긍정-과거-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64692</th>\n",
       "      <td>생명을 다투는 위기에 정쟁은 무의미하다</td>\n",
       "      <td>추론형</td>\n",
       "      <td>긍정</td>\n",
       "      <td>현재</td>\n",
       "      <td>확실</td>\n",
       "      <td>추론형-긍정-현재-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64693</th>\n",
       "      <td>조이시티는 코로나19 관련 상황이 안정화될 부서별로 각 때까지 탄력적으로 재택근무를...</td>\n",
       "      <td>사실형</td>\n",
       "      <td>긍정</td>\n",
       "      <td>현재</td>\n",
       "      <td>확실</td>\n",
       "      <td>사실형-긍정-현재-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64694</th>\n",
       "      <td>이 가운데 심사를 거쳐 사회적기업으로 인증된 19곳이다 곳은</td>\n",
       "      <td>사실형</td>\n",
       "      <td>긍정</td>\n",
       "      <td>현재</td>\n",
       "      <td>확실</td>\n",
       "      <td>사실형-긍정-현재-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64695</th>\n",
       "      <td>코로나19 사태가 언제까지 오리무중이다 지속될지</td>\n",
       "      <td>추론형</td>\n",
       "      <td>긍정</td>\n",
       "      <td>현재</td>\n",
       "      <td>확실</td>\n",
       "      <td>추론형-긍정-현재-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64696</th>\n",
       "      <td>최근 주변에 흔해진 당뇨병은 어떤 질환보다 혈관과 한다 관리에 주력해야 신경</td>\n",
       "      <td>추론형</td>\n",
       "      <td>긍정</td>\n",
       "      <td>현재</td>\n",
       "      <td>확실</td>\n",
       "      <td>추론형-긍정-현재-확실</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64697 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      문장   유형  극성  시제 확실성  \\\n",
       "0                                 누군가는 누군가는 살아남고 무대를 떠났다  사실형  긍정  과거  확실   \n",
       "1      현재 약 200여 명의 한국생애설계사들이 교육컨설턴트 상담사 등으로 활동하고 있으며...  사실형  긍정  현재  확실   \n",
       "2      한 활성화돼 말했다 업계의 어려움을 이해해주어 공항 면세점 임대료 감면을 연장해 주...  사실형  긍정  과거  확실   \n",
       "3      캐릭터 나열 순서 설정 기능을 통해 각 이용자가 보유한 캐릭터 중 원하는 캐릭터를 ...  사실형  긍정  과거  확실   \n",
       "4                              정도로 관람객이 거의 없을 주말이지만 한적했다  사실형  긍정  과거  확실   \n",
       "...                                                  ...  ...  ..  ..  ..   \n",
       "64692                              생명을 다투는 위기에 정쟁은 무의미하다  추론형  긍정  현재  확실   \n",
       "64693  조이시티는 코로나19 관련 상황이 안정화될 부서별로 각 때까지 탄력적으로 재택근무를...  사실형  긍정  현재  확실   \n",
       "64694                  이 가운데 심사를 거쳐 사회적기업으로 인증된 19곳이다 곳은  사실형  긍정  현재  확실   \n",
       "64695                         코로나19 사태가 언제까지 오리무중이다 지속될지  추론형  긍정  현재  확실   \n",
       "64696         최근 주변에 흔해진 당뇨병은 어떤 질환보다 혈관과 한다 관리에 주력해야 신경  추론형  긍정  현재  확실   \n",
       "\n",
       "              label  \n",
       "0      사실형-긍정-과거-확실  \n",
       "1      사실형-긍정-현재-확실  \n",
       "2      사실형-긍정-과거-확실  \n",
       "3      사실형-긍정-과거-확실  \n",
       "4      사실형-긍정-과거-확실  \n",
       "...             ...  \n",
       "64692  추론형-긍정-현재-확실  \n",
       "64693  사실형-긍정-현재-확실  \n",
       "64694  사실형-긍정-현재-확실  \n",
       "64695  추론형-긍정-현재-확실  \n",
       "64696  추론형-긍정-현재-확실  \n",
       "\n",
       "[64697 rows x 6 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['사실형', '추론형', '예측형', '대화형'], dtype=object),\n",
       " array(['긍정', '부정', '미정'], dtype=object),\n",
       " array(['현재', '과거', '미래'], dtype=object),\n",
       " array(['확실', '불확실'], dtype=object))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.유형.unique(), train.극성.unique(), train.시제.unique(), train.확실성.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['문장'] = train['문장'].apply(lambda x: re.sub(\"[^ A-Za-z0-9가-힣]\",\"\",x))\n",
    "train['문장'] = train['문장'].apply(lambda x: re.sub(\"[ +]\",\" \",x))\n",
    "\n",
    "test['문장'] = test['문장'].apply(lambda x: re.sub(\"[^ A-Za-z0-9가-힣]\",\"\",x))\n",
    "test['문장'] = test['문장'].apply(lambda x: re.sub(\"[ +]\",\" \",x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                       075포인트 금리 인상은 1994년 이후 28년 만에 처음이다\n",
       "1        이어 앞으로 전문가들과 함께 4주 단위로 상황을 재평가할 예정이라며 그 이전이라도 ...\n",
       "2        정부가 고유가 대응을 위해 7월부터 연말까지 유류세 인하 폭을 30에서 37까지 확대한다\n",
       "3        서울시는 올해 3월 즉시 견인 유예시간 60분을 제공하겠다고 밝혔지만 하루 만에 차...\n",
       "4                  익사한 자는 사다리에 태워 거꾸로 놓고 소금으로 코를 막아 가득 채운다\n",
       "                               ...                        \n",
       "16536    신동덤은 신비한 동물사전과 해리 포터 시리즈를 잇는 마법 어드벤처물로 전편에 이어 ...\n",
       "16537    수족냉증은 어릴 때부터 심했으며 관절은 어디 한 곳이 아니고 목 어깨 팔꿈치 등 허...\n",
       "16538    김금희 소설가는 계약서 조정이 그리 어려운가 작가를 격려한다면서 그런 문구 하나 고...\n",
       "16539    1만명이 넘는 방문자수를 기록한 이번 전시회는 총 77개 작품을 넥슨 사옥을 그대로...\n",
       "16540                                           목민심서의 내용이다\n",
       "Name: 문장, Length: 16541, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['문장']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/catSirup/KorEDA/blob/master/eda.py\n",
    "def swap_word(new_words):\n",
    "    random_idx_1 = random.randint(0, len(new_words)-1)\n",
    "    random_idx_2 = random_idx_1\n",
    "    counter = 0\n",
    "\n",
    "    while random_idx_2 == random_idx_1:\n",
    "        random_idx_2 = random.randint(0, len(new_words)-1)\n",
    "        counter += 1\n",
    "        if counter > 3:\n",
    "            return new_words\n",
    "\n",
    "    new_words[random_idx_1], new_words[random_idx_2] = new_words[random_idx_2], new_words[random_idx_1]\n",
    "    return new_words\n",
    "\n",
    "def random_swap(words, n):\n",
    "    new_words = words.copy()\n",
    "    for _ in range(n):\n",
    "        new_words = swap_word(new_words)\n",
    "    return new_words\n",
    "\n",
    "def text_aug(sentence, alpha_rs = 0.1, num_aug=3):\n",
    "    words = sentence.split(' ')\n",
    "    words = [word for word in words if word != \"\"]\n",
    "    num_words = len(words)\n",
    "\n",
    "    augmented_sentences = []\n",
    "    num_new_per_technique = num_aug\n",
    "\n",
    "    n_rs = max(1, int(alpha_rs*num_words))\n",
    "\n",
    "    for _ in range(num_new_per_technique):\n",
    "        a_words = random_swap(words, n_rs)\n",
    "        augmented_sentences.append(\" \".join(a_words))\n",
    "\n",
    "    augmented_sentences = [sentence for sentence in augmented_sentences]\n",
    "    random.shuffle(augmented_sentences)\n",
    "\n",
    "    if num_aug >= 1:\n",
    "        augmented_sentences = augmented_sentences[:num_aug]\n",
    "    else:\n",
    "        keep_prob = num_aug / len(augmented_sentences)\n",
    "        augmented_sentences = [s for s in augmented_sentences if random.uniform(0, 1) < keep_prob]\n",
    "    return augmented_sentences\n",
    "\n",
    "aug = train['문장'].apply(lambda x: text_aug(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp1 = train.copy()\n",
    "tmp1['문장'] = list(map(lambda x: x[0], aug))\n",
    "\n",
    "tmp2 = train.copy()\n",
    "tmp2['문장'] = list(map(lambda x: x[1], aug))\n",
    "\n",
    "tmp3 = train.copy()\n",
    "tmp3['문장'] = list(map(lambda x: x[2], aug))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>문장</th>\n",
       "      <th>유형</th>\n",
       "      <th>극성</th>\n",
       "      <th>시제</th>\n",
       "      <th>확실성</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>누군가는 누군가는 살아남고 무대를 떠났다</td>\n",
       "      <td>사실형</td>\n",
       "      <td>긍정</td>\n",
       "      <td>과거</td>\n",
       "      <td>확실</td>\n",
       "      <td>사실형-긍정-과거-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>현재 약 200여 명의 한국생애설계사들이 교육컨설턴트 상담사 등으로 활동하고 있으며...</td>\n",
       "      <td>사실형</td>\n",
       "      <td>긍정</td>\n",
       "      <td>현재</td>\n",
       "      <td>확실</td>\n",
       "      <td>사실형-긍정-현재-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>한 활성화돼 말했다 업계의 어려움을 이해해주어 공항 면세점 임대료 감면을 연장해 주...</td>\n",
       "      <td>사실형</td>\n",
       "      <td>긍정</td>\n",
       "      <td>과거</td>\n",
       "      <td>확실</td>\n",
       "      <td>사실형-긍정-과거-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>캐릭터 나열 순서 설정 기능을 통해 각 이용자가 보유한 캐릭터 중 원하는 캐릭터를 ...</td>\n",
       "      <td>사실형</td>\n",
       "      <td>긍정</td>\n",
       "      <td>과거</td>\n",
       "      <td>확실</td>\n",
       "      <td>사실형-긍정-과거-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>정도로 관람객이 거의 없을 주말이지만 한적했다</td>\n",
       "      <td>사실형</td>\n",
       "      <td>긍정</td>\n",
       "      <td>과거</td>\n",
       "      <td>확실</td>\n",
       "      <td>사실형-긍정-과거-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64692</th>\n",
       "      <td>생명을 다투는 위기에 정쟁은 무의미하다</td>\n",
       "      <td>추론형</td>\n",
       "      <td>긍정</td>\n",
       "      <td>현재</td>\n",
       "      <td>확실</td>\n",
       "      <td>추론형-긍정-현재-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64693</th>\n",
       "      <td>조이시티는 코로나19 관련 상황이 안정화될 부서별로 각 때까지 탄력적으로 재택근무를...</td>\n",
       "      <td>사실형</td>\n",
       "      <td>긍정</td>\n",
       "      <td>현재</td>\n",
       "      <td>확실</td>\n",
       "      <td>사실형-긍정-현재-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64694</th>\n",
       "      <td>이 가운데 심사를 거쳐 사회적기업으로 인증된 19곳이다 곳은</td>\n",
       "      <td>사실형</td>\n",
       "      <td>긍정</td>\n",
       "      <td>현재</td>\n",
       "      <td>확실</td>\n",
       "      <td>사실형-긍정-현재-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64695</th>\n",
       "      <td>코로나19 사태가 언제까지 오리무중이다 지속될지</td>\n",
       "      <td>추론형</td>\n",
       "      <td>긍정</td>\n",
       "      <td>현재</td>\n",
       "      <td>확실</td>\n",
       "      <td>추론형-긍정-현재-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64696</th>\n",
       "      <td>최근 주변에 흔해진 당뇨병은 어떤 질환보다 혈관과 한다 관리에 주력해야 신경</td>\n",
       "      <td>추론형</td>\n",
       "      <td>긍정</td>\n",
       "      <td>현재</td>\n",
       "      <td>확실</td>\n",
       "      <td>추론형-긍정-현재-확실</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64697 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      문장   유형  극성  시제 확실성  \\\n",
       "0                                 누군가는 누군가는 살아남고 무대를 떠났다  사실형  긍정  과거  확실   \n",
       "1      현재 약 200여 명의 한국생애설계사들이 교육컨설턴트 상담사 등으로 활동하고 있으며...  사실형  긍정  현재  확실   \n",
       "2      한 활성화돼 말했다 업계의 어려움을 이해해주어 공항 면세점 임대료 감면을 연장해 주...  사실형  긍정  과거  확실   \n",
       "3      캐릭터 나열 순서 설정 기능을 통해 각 이용자가 보유한 캐릭터 중 원하는 캐릭터를 ...  사실형  긍정  과거  확실   \n",
       "4                              정도로 관람객이 거의 없을 주말이지만 한적했다  사실형  긍정  과거  확실   \n",
       "...                                                  ...  ...  ..  ..  ..   \n",
       "64692                              생명을 다투는 위기에 정쟁은 무의미하다  추론형  긍정  현재  확실   \n",
       "64693  조이시티는 코로나19 관련 상황이 안정화될 부서별로 각 때까지 탄력적으로 재택근무를...  사실형  긍정  현재  확실   \n",
       "64694                  이 가운데 심사를 거쳐 사회적기업으로 인증된 19곳이다 곳은  사실형  긍정  현재  확실   \n",
       "64695                         코로나19 사태가 언제까지 오리무중이다 지속될지  추론형  긍정  현재  확실   \n",
       "64696         최근 주변에 흔해진 당뇨병은 어떤 질환보다 혈관과 한다 관리에 주력해야 신경  추론형  긍정  현재  확실   \n",
       "\n",
       "              label  \n",
       "0      사실형-긍정-과거-확실  \n",
       "1      사실형-긍정-현재-확실  \n",
       "2      사실형-긍정-과거-확실  \n",
       "3      사실형-긍정-과거-확실  \n",
       "4      사실형-긍정-과거-확실  \n",
       "...             ...  \n",
       "64692  추론형-긍정-현재-확실  \n",
       "64693  사실형-긍정-현재-확실  \n",
       "64694  사실형-긍정-현재-확실  \n",
       "64695  추론형-긍정-현재-확실  \n",
       "64696  추론형-긍정-현재-확실  \n",
       "\n",
       "[64697 rows x 6 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.concat([train,tmp1,tmp2,tmp3]).drop_duplicates(keep='first').sample(frac=1).reset_index(drop=True)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "checkpoint = \"kykim/electra-kor-base\"\n",
    "if checkpoint == 'paust/pko-t5-large':\n",
    "    tokenozer = T5TokenizerFast.from_pretrained(checkpoint)\n",
    "elif checkpoint == 'kykim/electra_kor_base':\n",
    "    tokenizer = ElectraTokenizerFast.from_pretrained(checkpoint)\n",
    "else:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "length = train['문장'].str.len().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels=None):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        item = {key:torch.tensor(val[idx]) for key,val in self.encodings.items()}\n",
    "        if self.labels:\n",
    "            st_type = self.labels['type'][idx]\n",
    "            st_polarity = self.labels['polarity'][idx]\n",
    "            st_tense = self.labels[\"tense\"][idx]\n",
    "            st_certainty = self.labels[\"certainty\"][idx]\n",
    "            item[\"labels\"] = torch.tensor(st_type), torch.tensor(st_polarity), torch.tensor(st_tense), torch.tensor(st_certainty)\n",
    "        \n",
    "        return item\n",
    "    def __len__(self):\n",
    "        return len(self.encodings[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    \"\"\" Focal Loss, as described in https://arxiv.org/abs/1708.02002.\n",
    "    It is essentially an enhancement to cross entropy loss and is\n",
    "    useful for classification tasks when there is a large class imbalance.\n",
    "    x is expected to contain raw, unnormalized scores for each class.\n",
    "    y is expected to contain class labels.\n",
    "    Shape:\n",
    "        - x: (batch_size, C) or (batch_size, C, d1, d2, ..., dK), K > 0.\n",
    "        - y: (batch_size,) or (batch_size, d1, d2, ..., dK), K > 0.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 alpha: Optional[Tensor] = None,\n",
    "                 gamma: float = 0.,\n",
    "                 reduction: str = 'mean',\n",
    "                 ignore_index: int = -100):\n",
    "        \"\"\"Constructor.\n",
    "        Args:\n",
    "            alpha (Tensor, optional): Weights for each class. Defaults to None.\n",
    "            gamma (float, optional): A constant, as described in the paper.\n",
    "                Defaults to 0.\n",
    "            reduction (str, optional): 'mean', 'sum' or 'none'.\n",
    "                Defaults to 'mean'.\n",
    "            ignore_index (int, optional): class label to ignore.\n",
    "                Defaults to -100.\n",
    "        \"\"\"\n",
    "        if reduction not in ('mean', 'sum', 'none'):\n",
    "            raise ValueError(\n",
    "                'Reduction must be one of: \"mean\", \"sum\", \"none\".')\n",
    "\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.ignore_index = ignore_index\n",
    "        self.reduction = reduction\n",
    "\n",
    "        self.nll_loss = nn.NLLLoss(\n",
    "            weight=alpha, reduction='none', ignore_index=ignore_index)\n",
    "\n",
    "    def __repr__(self):\n",
    "        arg_keys = ['alpha', 'gamma', 'ignore_index', 'reduction']\n",
    "        arg_vals = [self.__dict__[k] for k in arg_keys]\n",
    "        arg_strs = [f'{k}={v!r}' for k, v in zip(arg_keys, arg_vals)]\n",
    "        arg_str = ', '.join(arg_strs)\n",
    "        return f'{type(self).__name__}({arg_str})'\n",
    "\n",
    "    def forward(self, x: Tensor, y: Tensor) -> Tensor:\n",
    "        if x.ndim > 2:\n",
    "            # (N, C, d1, d2, ..., dK) --> (N * d1 * ... * dK, C)\n",
    "            c = x.shape[1]\n",
    "            x = x.permute(0, *range(2, x.ndim), 1).reshape(-1, c)\n",
    "            # (N, d1, d2, ..., dK) --> (N * d1 * ... * dK,)\n",
    "            y = y.view(-1)\n",
    "\n",
    "        unignored_mask = y != self.ignore_index\n",
    "        y = y[unignored_mask]\n",
    "        if len(y) == 0:\n",
    "            return torch.tensor(0.)\n",
    "        x = x[unignored_mask]\n",
    "\n",
    "        # compute weighted cross entropy term: -alpha * log(pt)\n",
    "        # (alpha is already part of self.nll_loss)\n",
    "        log_p = F.log_softmax(x, dim=-1)\n",
    "        ce = self.nll_loss(log_p, y)\n",
    "\n",
    "        # get true class column from each row\n",
    "        all_rows = torch.arange(len(x))\n",
    "        log_pt = log_p[all_rows, y]\n",
    "\n",
    "        # compute focal term: (1 - pt)^gamma\n",
    "        pt = log_pt.exp()\n",
    "        focal_term = (1 - pt)**self.gamma\n",
    "\n",
    "        # the full loss: -alpha * ((1 - pt)^gamma) * log(pt)\n",
    "        loss = focal_term * ce\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            loss = loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            loss = loss.sum()\n",
    "\n",
    "        return loss\n",
    "\n",
    "def focal_loss(alpha: Optional[Sequence] = None,\n",
    "               gamma: float = 0.,\n",
    "               reduction: str = 'mean',\n",
    "               ignore_index: int = -100,\n",
    "               device='cpu',\n",
    "               dtype=torch.float32) -> FocalLoss:\n",
    "    \"\"\"Factory function for FocalLoss.\n",
    "    Args:\n",
    "        alpha (Sequence, optional): Weights for each class. Will be converted\n",
    "            to a Tensor if not None. Defaults to None.\n",
    "        gamma (float, optional): A constant, as described in the paper.\n",
    "            Defaults to 0.\n",
    "        reduction (str, optional): 'mean', 'sum' or 'none'.\n",
    "            Defaults to 'mean'.\n",
    "        ignore_index (int, optional): class label to ignore.\n",
    "            Defaults to -100.\n",
    "        device (str, optional): Device to move alpha to. Defaults to 'cpu'.\n",
    "        dtype (torch.dtype, optional): dtype to cast alpha to.\n",
    "            Defaults to torch.float32.\n",
    "    Returns:\n",
    "        A FocalLoss object\n",
    "    \"\"\"\n",
    "    if alpha is not None:\n",
    "        if not isinstance(alpha, Tensor):\n",
    "            alpha = torch.tensor(alpha)\n",
    "        alpha = alpha.to(device=device, dtype=dtype)\n",
    "\n",
    "    fl = FocalLoss(\n",
    "        alpha=alpha,\n",
    "        gamma=gamma,\n",
    "        reduction=reduction,\n",
    "        ignore_index=ignore_index)\n",
    "    return fl\n",
    "        \n",
    "def compute_metrics(pred):\n",
    "    # label = [[cls1,cls2,...],]\n",
    "    # preds = n list\n",
    "    focal_loss = FocalLoss()\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions\n",
    "    f1 = []\n",
    "    focal = []\n",
    "    for i in range(4):\n",
    "        # focal.append(focal_loss(torch.tensor(preds[i], dtype=torch.float), torch.tensor(labels[::, i],dtype=torch.float)))\n",
    "        f1.append(f1_score(y_true = labels[::, i], y_pred = preds[i], average='weighted'))\n",
    "    return {\n",
    "        #'focal': sum(focal),\n",
    "        'f1-sum': sum(f1)/4\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElectraConfig {\n",
      "  \"_name_or_path\": \"kr.kim\",\n",
      "  \"architectures\": [\n",
      "    \"ElectraForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 42000\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config = AutoConfig.from_pretrained(checkpoint)\n",
    "config.name_or_path=\"kr.kim\"\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "유형 = LabelEncoder()\n",
    "유형.fit(train['유형'])\n",
    "\n",
    "극성 = LabelEncoder()\n",
    "극성.fit(train['극성'])\n",
    "\n",
    "시제 = LabelEncoder()\n",
    "시제.fit(train['시제'])\n",
    "\n",
    "확실성 = LabelEncoder()\n",
    "확실성.fit(train['확실성'])\n",
    "\n",
    "def encoding(X_train, X_val):\n",
    "    X_train[\"유형\"] = 유형.transform(X_train['유형'])\n",
    "    X_val[\"유형\"] = 유형.transform(X_val[\"유형\"])\n",
    "\n",
    "    X_train[\"극성\"] = 극성.transform(X_train['극성'])\n",
    "    X_val[\"극성\"] = 극성.transform(X_val[\"극성\"])\n",
    "\n",
    "    X_train[\"시제\"] = 시제.transform(X_train['시제'])\n",
    "    X_val[\"시제\"] = 시제.transform(X_val[\"시제\"])\n",
    "\n",
    "    X_train[\"확실성\"] = 확실성.transform(X_train['확실성'])\n",
    "    X_val[\"확실성\"] = 확실성.transform(X_val[\"확실성\"])\n",
    "\n",
    "    train_labels = {\n",
    "        'type': X_train['유형'].values,\n",
    "        'polarity': X_train['극성'].values,\n",
    "        'tense': X_train['시제'].values,\n",
    "        'certainty': X_train['확실성'].values\n",
    "    }\n",
    "\n",
    "    val_labels = {\n",
    "        'type': X_val['유형'].values,\n",
    "        'polarity': X_val['극성'].values,\n",
    "        'tense': X_val['시제'].values,\n",
    "        'certainty': X_val['확실성'].values\n",
    "    }\n",
    "\n",
    "    return train_labels, val_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recent_file(path):\n",
    "    file_name_and_time_lst = []\n",
    "    # 해당 경로에 있는 파일들을 생성시간을 함꼐 리스트로 넣어주고 역순으로 정렬\n",
    "    for f_name in os.listdir(f\"{path}\"):\n",
    "        written_time = os.path.getctime(f\"{path}/{f_name}\")\n",
    "        file_name_and_time_lst.append((f_name, written_time))\n",
    "\n",
    "    sorted_file_lst = sorted(file_name_and_time_lst, key=lambda x:x[1], reverse=True)\n",
    "    recent_file = sorted_file_lst[0]\n",
    "    recent_file_name = recent_file[0]\n",
    "    return f\"{path}/{recent_file_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomModel, self).__init__()\n",
    "        if checkpoint == 'monologg/kobigbird-bert-case':\n",
    "            config.attention_type = \"original_full\"\n",
    "            self.base_model = AutoModel.from_pretrained(checkpoint, config=config)\n",
    "        elif checkpoint == 'kykim/electra-kor-base':\n",
    "            self.base_model = ElectraModel.from_pretrained(checkpoint, config=config)\n",
    "        elif checkpoint == 'paust/pko-t5-large':\n",
    "            self.base_model = T5ForConditionalGeneration.from_pretrained(checkpoint, config=config)\n",
    "        else:\n",
    "            self.base_model = AutoModel.from_pretrained(checkpoint, config=config)\n",
    "       \n",
    "        try:\n",
    "            self.out = self.base_model.encoder.layer[-1].output.dense.out_features\n",
    "        except:\n",
    "            self.out = 768\n",
    "        \n",
    "        self.type_classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(in_features=self.out, out_features=4)\n",
    "        )\n",
    "        self.polarity_classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(in_features=self.out, out_features=3)\n",
    "        )\n",
    "        self.tense_classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(in_features=self.out, out_features=3)\n",
    "        )\n",
    "        self.certainty_classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(in_features=self.out, out_features=2)\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None, token_type_ids=None):\n",
    "        if checkpoint == \"paust/pko-t5-large\":\n",
    "            x = self.base_model(input_ids=input_ids, attention_mask=attention_mask, decoder_input_ids=input_ids)[0]\n",
    "        else:\n",
    "            x = self.base_model(input_ids=input_ids, attention_mask=attention_mask)[0]\n",
    "\n",
    "        type_output = self.type_classifier(x[:,0,:].view(-1,self.out))\n",
    "        polarity_output = self.polarity_classifier(x[:,0,:].view(-1,self.out))\n",
    "        tense_output = self.tense_classifier(x[:,0,:].view(-1,self.out))\n",
    "        certainty_output = self.certainty_classifier(x[:,0,:].view(-1,self.out))\n",
    "        return type_output, polarity_output, tense_output, certainty_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-4\n",
    "stop = 3\n",
    "epoch = 1000\n",
    "batch = 16\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tokenized = tokenizer(test[\"문장\"].tolist(),padding=True, truncation=True, max_length=length, return_tensors=\"pt\")\n",
    "test_dataset = Cust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CustomTrainer(Trainer):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args,**kwargs)\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.pop(\"labels\").to(torch.int64)\n",
    "        type_logit, polarity_logit, tense_logit, certainty_logit = model(**inputs)\n",
    "\n",
    "        criterion = {\n",
    "            'type' : FocalLoss().to(device),\n",
    "            'polarity': FocalLoss().to(device),\n",
    "            'tense': FocalLoss().to(device),\n",
    "            'certainty': FocalLoss().to(device)\n",
    "        }\n",
    "        loss = criterion['type'](type_logit, labels[::,0]) + \\\n",
    "                criterion['polarity'](polarity_logit, labels[::,1]) + \\\n",
    "                criterion['tense'](tense_logit,labels[::,2]) + \\\n",
    "                criterion['certainty'](certainty_logit,labels[::,3])\n",
    "        \n",
    "        outputs = None,\\\n",
    "                torch.argmax(type_logit, dim=1),\\\n",
    "                torch.argmax(polarity_logit, dim=1),\\\n",
    "                torch.argmax(tense_logit, dim=1),\\\n",
    "                torch.argmax(certainty_logit,dim=1)\n",
    "        \n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden_layers : 12\n",
      "now_hidden_layers : 12\n",
      "Round 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file pytorch_model.bin from cache at C:\\Users\\kyj09/.cache\\huggingface\\hub\\models--kykim--electra-kor-base\\snapshots\\8599418d72f5dcb21ae3972ba2405f88c819b195\\pytorch_model.bin\n",
      "Some weights of the model checkpoint at kykim/electra-kor-base were not used when initializing ElectraModel: ['discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.weight']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of ElectraModel were initialized from the model checkpoint at kykim/electra-kor-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use ElectraModel for predictions without further training.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "Using cuda_amp half precision backend\n",
      "c:\\Users\\kyj09\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 51757\n",
      "  Num Epochs = 1000\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 256\n",
      "  Gradient Accumulation steps = 16\n",
      "  Total optimization steps = 202000\n",
      "  Number of trainable parameters = 117715980\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9b966efcda34ec68b19d4ef24b4a9a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/202000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 12940\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3559, 'learning_rate': 9.995148514851486e-05, 'epoch': 0.49}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "574d712ea5ac44b0861c41434424682c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/809 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to fold_0\\checkpoint-100\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.858784019947052, 'eval_f1-sum': 0.9218885124817623, 'eval_runtime': 54.984, 'eval_samples_per_second': 235.341, 'eval_steps_per_second': 14.713, 'epoch': 0.49}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 12940\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7944, 'learning_rate': 9.99019801980198e-05, 'epoch': 0.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27453a3ac8ec473d893c1bfd1afe4250",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/809 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to fold_0\\checkpoint-200\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6629049777984619, 'eval_f1-sum': 0.9387740821106906, 'eval_runtime': 54.7857, 'eval_samples_per_second': 236.193, 'eval_steps_per_second': 14.767, 'epoch': 0.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 12940\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5496, 'learning_rate': 9.985247524752476e-05, 'epoch': 1.48}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43b93234e55f46f5843d55ec616ee4ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/809 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to fold_0\\checkpoint-300\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5150865912437439, 'eval_f1-sum': 0.956678700559104, 'eval_runtime': 54.9087, 'eval_samples_per_second': 235.664, 'eval_steps_per_second': 14.734, 'epoch': 1.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [fold_0\\checkpoint-100] due to args.save_total_limit\n"
     ]
    }
   ],
   "source": [
    "print(f'hidden_layers : {config.num_hidden_layers}')\n",
    "# config.num_hidden_layers = 10\n",
    "print(f'now_hidden_layers : {config.num_hidden_layers}')\n",
    "\n",
    "kf = KFold(n_splits=5, random_state=seed, shuffle=True)\n",
    "for i, (train_index, test_index) in enumerate(kf.split(train)):\n",
    "    print(f'Round {i}')\n",
    "    X_train, X_val = train.loc[train_index, :], train.loc[test_index, :]\n",
    "    train_labels, val_labels = encoding(X_train, X_val)\n",
    "    token_train, token_val = tokenizer(X_train.문장.tolist(), padding=True, truncation=True, max_length=length), tokenizer(X_val.문장.tolist(), padding=True, truncation=True, max_length=length)\n",
    "    train_dataset, val_dataset = CustomDataset(token_train, train_labels), CustomDataset(token_val, val_labels)\n",
    "    model = CustomModel()\n",
    "    model.to(device)\n",
    "    args = TrainingArguments(run_name = f'fold_{i}',                                # 모델이름\n",
    "                             output_dir= f\"fold_{i}\",                               # 모델저장경로\n",
    "                             evaluation_strategy=\"steps\",                           # 모델의 평가를 언제 진행할지\n",
    "                             eval_steps=100,                                        # 500 스텝 마다 모델 평가\n",
    "                             save_steps=100,                                        # 500 스텝 마다 모델 저장\n",
    "                             save_total_limit = 2,                                  # 저장할 모델의 갯수\n",
    "                             logging_steps=100,                                     # 학습로스 로깅\n",
    "                             per_device_train_batch_size=batch,                     # GPU에 학습데이터를 몇개씩 올려서 학습할지\n",
    "                             per_device_eval_batch_size=batch,                      # GPU에 학습데이터를 몇개씩 올려서 평가할지\n",
    "                             gradient_accumulation_steps=16,                        # 가상배치\n",
    "                             num_train_epochs=epoch,                                # 전체 학습 진행 횟수\n",
    "                             learning_rate=lr,                                      # 학습률 정의 \n",
    "                             seed=seed,                                             # seed\n",
    "                             load_best_model_at_end=True,                           # 평가기준 스코어가 좋은 모델만 저장할지 여부\n",
    "                             fp16=True,\n",
    "                             do_train=True,\n",
    "                             do_eval=True,\n",
    "                             # metric_for_best_model\n",
    "                             # greater_is_better = True,\n",
    "    )\n",
    "    trainer = CustomTrainer(model=model,\n",
    "                            args=args,                                                        # args\n",
    "                            train_dataset=train_dataset,                                      # 학습데이터\n",
    "                            eval_dataset=val_dataset,                                         # validation 데이터\n",
    "                            compute_metrics=compute_metrics,                                  # 모델 평가 방식\n",
    "                            callbacks=[EarlyStoppingCallback(early_stopping_patience=stop)],) # callback\n",
    "    trainer.train()\n",
    "    del model\n",
    "    del trainer\n",
    "    gc.collect() # python 자원 관리 \n",
    "    torch.cuda.empty_cache() # gpu 자원관리   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recent_file(path):\n",
    "    file_name_and_time_lst = []\n",
    "    # 해당 경로에 있는 파일들의 생성시간을 함께 리스트로 넣어줌. \n",
    "    for f_name in os.listdir(f\"{path}\"):\n",
    "        written_time = os.path.getctime(f\"{path}/{f_name}\")\n",
    "        file_name_and_time_lst.append((f_name, written_time))\n",
    "    # 생성시간 역순으로 정렬하고, \n",
    "    sorted_file_lst = sorted(file_name_and_time_lst, key=lambda x: x[1], reverse=True)\n",
    "    # 가장 앞에 이는 놈을 넣어준다.\n",
    "    recent_file = sorted_file_lst[0]\n",
    "    recent_file_name = recent_file[0]\n",
    "    return f\"{path}/{recent_file_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect() # python 자원 관리 \n",
    "torch.cuda.empty_cache() # gpu 자원관리\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "tokenized = tokenizer(test.문장.tolist(), padding=True, truncation=True, max_length=length, return_tensors=\"pt\")\n",
    "test_dataset = CustomDataset(tokenized, None)\n",
    "test_args = TrainingArguments(\n",
    "    output_dir = './',\n",
    "    do_train = False,\n",
    "    do_predict = True,\n",
    "    per_device_eval_batch_size = 512,   \n",
    "    dataloader_drop_last = False    \n",
    ")\n",
    "\n",
    "tmp = 0\n",
    "while os.path.isdir(f'fold_{tmp}'):\n",
    "    tmp += 1\n",
    "\n",
    "test_results = []\n",
    "for i in range(tmp):\n",
    "    print(f'Round {i}')\n",
    "    # model = AutoModel.from_pretrained(recent_file('custom_model'), config=config)\n",
    "    model = CustomModel().to(device)\n",
    "    model.load_state_dict(torch.load(f\"{recent_file(f'fold_{i}')}/pytorch_model.bin\"))\n",
    "    trainer = CustomTrainer(\n",
    "                  model = model, \n",
    "                  args = test_args, \n",
    "                  compute_metrics = compute_metrics)\n",
    "    test_results.append(trainer.predict(test_dataset))\n",
    "    del model\n",
    "    del trainer\n",
    "    gc.collect() # python 자원 관리 \n",
    "    torch.cuda.empty_cache() # gpu 자원관리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['유형'] = list(map(lambda x : 유형.inverse_transform([np.argmax(x)]), sum(list(map(lambda x: x.predictions[0], test_results)))/len(test_results)))\n",
    "test['극성'] = list(map(lambda x : 극성.inverse_transform([np.argmax(x)]), sum(list(map(lambda x: x.predictions[1], test_results)))/len(test_results)))\n",
    "test['시제'] = list(map(lambda x : 시제.inverse_transform([np.argmax(x)]), sum(list(map(lambda x: x.predictions[2], test_results)))/len(test_results)))\n",
    "test['확실성'] = list(map(lambda x : 확실성.inverse_transform([np.argmax(x)]), sum(list(map(lambda x: x.predictions[3], test_results)))/len(test_results)))\n",
    "\n",
    "test['유형'] = list(map(lambda x : x[0], test['유형']))\n",
    "test['극성'] = list(map(lambda x : x[0], test['극성']))\n",
    "test['시제'] = list(map(lambda x : x[0], test['시제']))\n",
    "test['확실성'] = list(map(lambda x : x[0], test['확실성']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['label'] = test['유형'] + '-' + test['극성'] + '-' + test['시제'] + '-' + test['확실성']\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('sample_submission.csv')\n",
    "sub['label'] = test['label']\n",
    "tmp = 0\n",
    "while os.path.exists(f'제출{tmp}.csv'):\n",
    "    tmp += 1\n",
    "sub.to_csv(f'제출{tmp}.csv', index=False, mode='w')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dc8fef993c398d68c6278bc760114fa0a752364ed2dc70eb55c44011e1c2ffe7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
